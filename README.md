# Conversational-chatbot-with-finutuned-BART

**Fineâ€‘Tuned Conversational Chatbot using DioloGPT with BART for Summarization**

A twoâ€‘stage, summaryâ€‘driven conversational chatbot that uses a LoRAâ€‘adapted BART summarizer and DialoGPT generator.  Summaries of the dialogue history are generated onâ€‘theâ€‘fly and used as context to produce coherent, contextâ€‘aware responses.

---

## Repository Structure

```plaintext
â”œâ”€â”€â”€â”€ Task1_Dataset_preperation.ipynb     # Generate groundâ€‘truth summaries using Llamaâ€¯3 on DailyDialog
â”‚â”€â”€â”€â”€ Task2_Finetune_BARTXsum.ipynb        # Fineâ€‘tune BARTâ€‘Largeâ€‘XSum with LoRA adapters
â”‚â”€â”€â”€â”€ Loss_evaluation_and_chatbot.ipynb # Evaluate losses & launch interactive chatbot demo
â”‚
â”œâ”€â”€ data/                             # Processed dataset and Llamaâ€¯3â€“generated summaries
â”‚   â”œâ”€â”€ Llama_summaries.csv            # Golden summaries from Llamaâ€¯3 (2,000 conversations) with Raw and preprocessed dialogues
â”‚   â”œâ”€â”€ bartXsum_summaries.csv                    
â”‚   â”œâ”€â”€ bartXsumFinetuned_summaries.csv
â”‚   â””â”€â”€ bartXsum_val_summaries.csv
â”‚
â”œâ”€â”€ model/                            # Final checkpoint and adapter files
â”‚   â”œâ”€â”€ checkpoint-2430/              # LoRAâ€‘adapted BART weights and config
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â”œâ”€â”€ merges.txt
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ vocab.json
â”‚   â””â”€â”€ training_args.bin             # Training arguments (optional)
â”‚
â”œâ”€â”€ requirements.txt                  # Python dependencies and versions
â””â”€â”€ README.md                         # This file
```

---

## ğŸš€ Quick Start

1. **Clone the repository**

   ```bash
   git clone https://github.com/Tanmay-jam/Conversational-chatbot-with-finetuned-BART.git
   cd Conversational-chatbot-with-finetuned-BART
   ```

2. **Set up a Python environment**

   ```bash
   python3 -m venv venv
   source venv/bin/activate        # Linux/macOS
   venv\Scripts\activate         # Windows
   pip install -r requirements.txt
   ```

3. **Run the notebooks**

   - **01\_data\_preparation.ipynb**: Download DailyDialog, generate Llamaâ€¯3 summaries via Ollama.
   - **02\_finetune\_bart.ipynb**: Fineâ€‘tune BARTâ€‘Largeâ€‘XSum on the custom dataset with PEFT/LoRA.
   - **03\_evaluate\_and\_chatbot.ipynb**: Evaluate preâ€‘ and postâ€‘finetuning metrics (ROUGE, METEOR, BERTScore) and launch an interactive chatbot using the summarizer + DialoGPT.
   - code to load model is provided in the notebook

4.

   Enter your message at the prompt and watch the summaryâ€‘driven chatbot respond in real time!

---

## ğŸ“‘ Notebooks Details

- **01\_data\_preparation.ipynb**\
  â€¢ Imports the DailyDialog dataset using `datasets`.\
  â€¢ Preprocesses dialogues and formats them for summarization.\
  â€¢ Uses Ollamaâ€™s Llamaâ€¯3 endpoint to generate â€œgoldâ€ summaries for 2,000 conversations.

- **02\_finetune\_bart.ipynb**\
  â€¢ Loads `facebook/bart-large-xsum` and applies LoRA adapters (via `peft`).\
  â€¢ Fineâ€‘tunes only adapter layers on the synthetic summaries.\
  â€¢ Saves the final adapter checkpoint under `model/checkpoint-2430/`.

- **03\_evaluate\_and\_chatbot.ipynb**\
  â€¢ Computes evaluation metrics (ROUGEâ€‘1/2/L, METEOR, BERTScore) before vs. after fineâ€‘tuning.\
  â€¢ Demonstrates an endâ€‘toâ€‘end chat loop:  summarize â†’ condition DialoGPT â†’ generate.

---

## ğŸ›  Requirements

```text
python>=3.8
transformers>=4.30.0
datasets
peft
ollama        # to run Llamaâ€¯3 locally
rouge_score
meteor_score
bert-score
diffusers    # if needed for other tasks
```

Install everything via:

```bash
pip install -r requirements.txt
```

---

## ğŸ”§ Usage Example

```
User: Hi there!
Bot: Hello! How can I assist you today?
User: Tell me a joke.
Bot: Why did the scarecrow win an award? Because he was outstanding in his field! 
```

---

## ğŸ“Š Evaluation Results

| Metric    | Before Fineâ€‘tuning | After Fineâ€‘tuning |
| --------- | ------------------ | ----------------- |
| ROUGEâ€‘1   | 0.17               | 0.42              |
| ROUGEâ€‘2   | 0.033              | 0.12              |
| ROUGEâ€‘L   | 0.13               | 0.32              |
| METEOR    | 0.17               | 0.38              |
| BERTScore | 0.43               | 0.64             |

*(Values are illustrativeâ€”see ********************************************************************************`03_evaluate_and_chatbot.ipynb`******************************************************************************** for exact numbers.)*

---


## ğŸ¤ Contributing

Contributions and issues are welcome! Please open a GitHub issue or pull request.

---

## ğŸ“œ License

This project is released under the Apache License. See `LICENSE` for details.

---

*Happy summarizing & chatting!*

